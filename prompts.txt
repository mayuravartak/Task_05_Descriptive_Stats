LLM Prompt Collection – Task 05
Syracuse University Women's Lacrosse Dataset (Public Stats)
Research Goal: Evaluate how accurately a large language model (LLM) can interpret and reason about tabular sports data.


Prompt 1: Basic Factual Understanding
Prompt:
“How many total games did the Syracuse Women’s Lacrosse team play during the season, and what was their final win–loss record?”
Goal:
To test whether the LLM can correctly interpret basic dataset structure and perform simple counting and aggregation.
Reasoning Type:
Factual recall and aggregation


Prompt 2: Analytical Insight
Prompt:
“Which player was the top performer this season based on total goals and assists combined?”
Goal:
To test if the LLM can perform multi-column analysis (summing Goals + Assists) and identify a player based on composite metrics.
Reasoning Type:
Analytical / ranking-based reasoning


Prompt 3: Strategic Reasoning
Prompt:
“As a coach, if I wanted to win two more games next season, should I focus on improving offense or defense, and which player could be a game changer?”
Goal:
To challenge the LLM’s ability to interpret performance trends, compare offensive vs defensive stats, and form a strategic recommendation using contextual reasoning.
Reasoning Type:
Causal / prescriptive reasoning


Notes:
1. These prompts were executed sequentially in ChatGPT (GPT-4).
2. Each response was validated against descriptive statistics generated by stats_verification.py.
3. Evaluation results are recorded separately in llm_response_summary.txt.
